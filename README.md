#  Cheshire: Una IA Conversacional Experta en "Alicia en el PaÃ­s de las Maravillas" ğŸ±

Â¡Bienvenido! Este proyecto es una inmersiÃ³n profunda en la creaciÃ³n de una IA experta y con personalidad, utilizando una arquitectura RAG (Retrieval-Augmented Generation) de principio a fin. El resultado es un chatbot con el que puedes conversar sobre "Alicia en el PaÃ­s de las Maravillas" en dos modos: como un Asistente Factual o como el enigmÃ¡tico Gato de Cheshire.

### âœ¨ Demo en AcciÃ³n

![Demo del Chatbot de Alicia](assets/demo.gif)
*(Nota: La inicializaciÃ³n del sistema en la primera pregunta tarda aproximadamente un minuto. Las respuestas posteriores son mucho mÃ¡s rÃ¡pidas.)*

---

## ğŸ¯ MotivaciÃ³n

El objetivo era construir un sistema RAG robusto, diseÃ±ado a medida para un texto literario complejo, que fuera capaz de:
1.  **Responder preguntas con alta precisiÃ³n**, basÃ¡ndose Ãºnicamente en el contenido del libro.
2.  **Evitar las "alucinaciones"** o invenciÃ³n de informaciÃ³n, un problema comÃºn en los LLMs.
3.  **Adoptar una personalidad creativa y consistente** sin sacrificar la veracidad de los datos.

## ğŸ› ï¸ Arquitectura y Stack TecnolÃ³gico

El sistema sigue un pipeline completo desde el PDF hasta la interfaz interactiva, todo contenido dentro de un Ãºnico notebook para facilitar su ejecuciÃ³n.

**Pipeline "Todo en Uno" (`Alicia_Chatbot.ipynb`):**
1.  **Procesamiento de Datos:**
    - Limpieza automÃ¡tica de un PDF del libro.
    - **Chunking semÃ¡ntico y jerÃ¡rquico** que respeta la estructura de capÃ­tulos.
    - GeneraciÃ³n de embeddings con los modelos de **OpenAI**.
    - CreaciÃ³n de un Ã­ndice vectorial en memoria con **FAISS**.
2.  **Pipeline de RAG:**
    - **BÃºsqueda HÃ­brida:** Combina la bÃºsqueda vectorial (FAISS) con la bÃºsqueda por palabras clave (**BM25**). Un sistema de pesos dinÃ¡micos analiza la pregunta para optimizar la estrategia.
    - **Reranking de PrecisiÃ³n:** Un modelo **Cross-Encoder** (`sentence-transformers`) refina los resultados para asegurar la mÃ¡xima relevancia.
    - **GeneraciÃ³n:** Se utiliza **Gemini 1.5 Flash** de Google AI, guiado por un sistema de **Prompt Engineering avanzado** para adoptar las personalidades.
3.  **Interfaz Interactiva:** Una aplicaciÃ³n web construida con **Gradio**.

### ğŸš€ Stack Principal
- **Lenguaje:** Python
- **LLM:** Google Gemini 1.5 Flash
- **Embeddings:** OpenAI `text-embedding-3-small`
- **BÃºsqueda Vectorial:** FAISS
- **BÃºsqueda por Palabras Clave:** `rank-bm25`
- **Reranking:** `sentence-transformers`
- **Framework de OrquestaciÃ³n:** LangChain
- **Interfaz:** Gradio

---

## ğŸš€ CÃ³mo Ejecutarlo (MÃ©todo Recomendado: Google Drive + Colab)

Este mÃ©todo es el mÃ¡s robusto, ya que mantiene todos tus archivos organizados y persistentes en un solo lugar.

**1. Prepara tu Entorno en Google Drive:**
   - Clona o descarga este repositorio y sube la carpeta `Alicia-RAG-Chatbot` completa a la raÃ­z de tu Google Drive.
   - Dentro de la carpeta del proyecto en Google Drive, renombra `.env.example` a `.env` y aÃ±ade tus claves de API de OpenAI y Google AI Studio.

**2. Ejecuta el Notebook en Google Colab:**
   - Navega a la carpeta del proyecto en tu Google Drive y abre el notebook `Alicia_Chatbot.ipynb`.
   - Arrastra y suelta el archivo PDF del libro desde tu ordenador al panel de los archivos de google colab, de cualquir forma no olvides de modificar esta ruta para procesar el libro, en mi caso es:
     `pdf_path = "/content/119-2014-02-19-Carroll.AliciaEnElPaisDeLasMaravillas (1).pdf"`.
   - **Â¡Paso CrÃ­tico!** Ejecuta la **primera celda de cÃ³digo**. Esta celda **montarÃ¡ tu Google Drive**, dÃ¡ndole al notebook acceso a tu PDF, claves de API y assets. DeberÃ¡s autorizar la conexiÃ³n.
   - Una vez montado el Drive, ejecuta todas las celdas restantes (`Entorno de ejecuciÃ³n` > `Ejecutar todo`).

**3. Â¡Disfruta de la AplicaciÃ³n!**
   - El notebook procesarÃ¡ el libro, crearÃ¡ los Ã­ndices y lanzarÃ¡ la interfaz de Gradio en la salida de la Ãºltima celda.
   - **Recuerda:** La **primera pregunta** que hagas serÃ¡ mÃ¡s lenta mientras se inicializan todos los modelos en memoria.

## ğŸ”® PrÃ³ximos Pasos

El siguiente desafÃ­o es evolucionar esta arquitectura a medida en una **plataforma modular y escalable**, separando el pre-procesamiento de la aplicaciÃ³n principal para poder tomar *cualquier* libro y convertirlo en una base de conocimiento conversacional e inteligente.
